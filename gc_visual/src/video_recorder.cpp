/** @file
 * @brief TODO: Brief docstring.
 *
 * TODO: More documentation here
 *
 * Copyright (C) 2025 MPK Software, St.-Petersburg, Russia
 *
 * @author Stepan Orlov <majorsteve@mail.ru>
 */

// Generated by Google Gemini and further edited manually

#include "gc_visual/video_recorder.hpp"

#include <QDebug>
#include <QMutex>
#include <QQueue>
#include <QThread>
#include <QWaitCondition>

// FFmpeg includes (usually requires C-linkage)
extern "C" {
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
#include <libavutil/imgutils.h>
#include <libavutil/opt.h>
}

class VideoRecorder::Impl final : public QThread
{
public:
    explicit Impl(VideoRecorder* parent) :
        QThread{parent},
        parent_{parent}
    {};

    bool start(const QString& file_name, int width, int height,
               const VideoRecorderOptions& options);
    auto status() const noexcept -> VideoRecorderStatus;
    void request_stop();
    void enqueue_frame(const QImage& frame);

protected:
    auto run() -> void override;

private:

    // Helper functions for FFmpeg setup and cleanup
    bool setupFFmpeg(const QString& file_name, int width, int height,
                     const VideoRecorderOptions& options);
    void cleanupFFmpeg();
    bool encodeFrame(const QImage& frame);

    VideoRecorder* parent_;

    // Thread safety for the frame queue
    QMutex mutex_;
    QWaitCondition waitCondition_;

    // Queue to hold frames waiting to be encoded (QImage objects are copied)
    QQueue<QImage> frameQueue_;

    // State flags
    std::atomic<VideoRecorderStatus> status_ {VideoRecorderStatus::Ready};
    std::atomic<bool> stop_requested_{false};

    // FFmpeg structures
    AVFormatContext *formatContext_ = nullptr;
    AVCodecContext *codecContext_ = nullptr;
    AVStream *videoStream_ = nullptr;
    SwsContext *swsContext_ = nullptr;
    AVFrame *frame_ = nullptr;
    int64_t frameCount_ = 0;
    int width_ = 0;
    int height_ = 0;
    int fps_ = 0;
};

// --- Helper Macro for FFmpeg Error Checking ---
#define FF_CHECK(result, error_message) \
    if (result < 0) { \
        char errbuf[AV_ERROR_MAX_STRING_SIZE]; \
        av_make_error_string(errbuf, AV_ERROR_MAX_STRING_SIZE, result); \
        emit parent_->error(QString(error_message) + \
            " FFmpeg Error: " + errbuf); \
        return false; \
    }


bool VideoRecorder::Impl::start(
    const QString& file_name, int width, int height,
    const VideoRecorderOptions& options)
{
    if (status_ != VideoRecorderStatus::Ready) {
        qWarning() << "Recording is already running.";
        return false;
    }

    if (!setupFFmpeg(file_name, width, height, options)) {
        cleanupFFmpeg();
        return false;
    }

    // Reset state and start the thread
    frameCount_ = 0;
    stop_requested_ = false;
    status_ = VideoRecorderStatus::Recording;
    QThread::start();
    return true;
}

void VideoRecorder::Impl::request_stop()
{
    if (status_ != VideoRecorderStatus::Recording)
        return;

    stop_requested_ = true;
    waitCondition_.wakeAll();
}

auto VideoRecorder::Impl::status() const noexcept -> VideoRecorderStatus
{
    return status_;
}

void VideoRecorder::Impl::enqueue_frame(const QImage& frame)
{
    if (status_ != VideoRecorderStatus::Recording)
        return;

    // Check frame size consistency
    if (frame.width() != width_ || frame.height() != height_)
    {
        emit parent_->error("Frame size mismatch detected! Skipping frame.");
        return;
    }

    QMutexLocker locker(&mutex_);
    // IMPORTANT: Make a copy of the QImage data as the original may be released
    // or modified by the sender after the signal returns.
    frameQueue_.enqueue(frame.copy());
    waitCondition_.wakeOne();
}

void VideoRecorder::Impl::run()
{
    qDebug() << "VideoRecorder worker thread started.";

    while (!stop_requested_)
    {
        QImage nextFrame;

        // --- Producer-Consumer Wait Loop ---
        mutex_.lock();
        if (frameQueue_.isEmpty() && !stop_requested_) {
            // Wait for a new frame to be added or a stop request
            waitCondition_.wait(&mutex_);
        }

        if (!frameQueue_.isEmpty()) {
            nextFrame = frameQueue_.dequeue();
        }
        mutex_.unlock();
        // --- End Wait Loop ---

        if (stop_requested_) {
            // Drain the queue if there are frames left to encode before exit
            while (!frameQueue_.isEmpty()) {
                nextFrame = frameQueue_.dequeue();
                encodeFrame(nextFrame);
            }
            break; // Exit the loop
        }

        if (!nextFrame.isNull()) {
            if (!encodeFrame(nextFrame)) {
                // An encoding error occurred.
                // The error signal is already emitted in encodeFrame
                break;
            }
        }
    }

    // Flush the encoder and close the file
    qDebug() << "Flushing encoder and cleaning up FFmpeg resources...";

    // Encode any residual delayed frames
    encodeFrame({});

    // Write the trailer (final file structure)
    if (formatContext_ && av_write_trailer(formatContext_) < 0) {
        qWarning() << "Error writing trailer.";
    }

    cleanupFFmpeg();
    qDebug() << "VideoRecorder worker thread finished.";
    status_ = VideoRecorderStatus::Ready;
}

// --- FFmpeg Encoding and Setup ---

bool VideoRecorder::Impl::setupFFmpeg(
    const QString& file_name, int width, int height,
    const VideoRecorderOptions& options)
{
    width_ = width;
    height_ = height;
    fps_ = options.fps;
    auto filename_str = file_name.toStdString();
    const char *c_filename = filename_str.c_str();

    // 1. Allocate the output format context
    int ret = avformat_alloc_output_context2(
        &formatContext_, NULL, NULL, c_filename);
    FF_CHECK(ret, "Could not allocate output format context.");

    // 2. Find the encoder (H.264 is a good default)
    const AVCodec *codec = avcodec_find_encoder(
        formatContext_->oformat->video_codec);
    if (!codec) {
        emit parent_->error("Could not find encoder for video stream.");
        return false;
    }

    // 3. Create a new video stream
    videoStream_ = avformat_new_stream(formatContext_, codec);
    if (!videoStream_) {
        emit parent_->error("Could not create new video stream.");
        return false;
    }
    videoStream_->id = formatContext_->nb_streams - 1;

    // 4. Allocate and configure the codec context
    codecContext_ = avcodec_alloc_context3(codec);
    if (!codecContext_) {
        emit parent_->error("Could not allocate codec context.");
        return false;
    }

    // Set parameters
    codecContext_->codec_id = codec->id;
    codecContext_->bit_rate = options.bit_rate;
    codecContext_->width = width_;
    codecContext_->height = height_;
    codecContext_->time_base = (AVRational){1, fps_};
    codecContext_->framerate = (AVRational){fps_, 1};
    codecContext_->gop_size = 10; // Group of Pictures - keyframe interval
    codecContext_->max_b_frames = 1;
    codecContext_->pix_fmt = AV_PIX_FMT_YUV420P; // Widely compatible format

    // Example for better quality but slower encoding:
    if (codec->id == AV_CODEC_ID_H264) {
        if (options.h264_preset)
            av_opt_set(
                codecContext_->priv_data,
                "preset",
                options.h264_preset->c_str(),
                0);
        // "preset" can be: ultrafast, superfast, veryfast, faster, fast,
        // medium (default), slow, slower, veryslow

        // You can also target a specific quality level (CRF) instead of
        // bitrate (CBR/VBR):
        // 0 (lossless) to 51 (worst quality). 23 is a good default.
        // av_opt_set_int(codecContext_->priv_data, "crf", 23, 0);
        if (options.h264_quality)
        av_opt_set_int(
            codecContext_->priv_data, "crf", *options.h264_quality, 0);
        // NOTE: If you set 'crf', FFmpeg might ignore 'bit_rate'.
        // Choose one control method.
    }

    if (formatContext_->oformat->flags & AVFMT_GLOBALHEADER) {
        codecContext_->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
    }

    // 5. Open the codec
    ret = avcodec_open2(codecContext_, codec, NULL);
    FF_CHECK(ret, "Could not open video codec.");

    // In VideoRecorder::setupFFmpeg, after opening m_codecContext:

    // Set the stream time base for the container format
    videoStream_->time_base = codecContext_->time_base;

    // 6. Copy codec parameters to stream
    ret = avcodec_parameters_from_context(
        videoStream_->codecpar, codecContext_);
    FF_CHECK(ret, "Could not copy parameters to stream.");

    // 7. Allocate frame for encoding
    frame_ = av_frame_alloc();
    if (!frame_) {
        emit parent_->error("Could not allocate AVFrame.");
        return false;
    }
    frame_->format = codecContext_->pix_fmt;
    frame_->width  = codecContext_->width;
    frame_->height = codecContext_->height;

    // Allocate memory for the frame data
    ret = av_frame_get_buffer(frame_, 32);
    FF_CHECK(ret, "Could not allocate frame data buffers.");

    // 8. Open the output file
    if (!(formatContext_->oformat->flags & AVFMT_NOFILE)) {
        ret = avio_open(&formatContext_->pb, c_filename, AVIO_FLAG_WRITE);
        FF_CHECK(ret, "Could not open output file.");
    }

    // 9. Write the file header
    ret = avformat_write_header(formatContext_, NULL);
    FF_CHECK(ret, "Error writing file header.");

    return true;
}

bool VideoRecorder::Impl::encodeFrame(const QImage& frame)
{
    if (frame.isNull()) {

        // NULL frame is a signal to flush the encoder
        int ret = avcodec_send_frame(codecContext_, NULL);
        if (ret < 0 && ret != AVERROR_EOF) {
            FF_CHECK(ret, "Error sending flush signal to encoder.");
            return false;
        }
        // Proceed immediately to the packet receiving loop to drain the buffer
    }
    else
    {
        // 1. Convert QImage to AVFrame's pixel format (YUV420P)

        // Ensure the QImage is in a format we can easily convert from
        // (e.g., RGB32)
        QImage rgbFrame = frame.convertToFormat(QImage::Format_RGB32);

        // Initialize SwsContext (Scale/Convert context) if not done
        if (!swsContext_) {
            swsContext_ = sws_getContext(
                width_, height_, AV_PIX_FMT_RGB32, // Input
                width_, height_, codecContext_->pix_fmt, // Output
                SWS_BICUBIC, NULL, NULL, NULL);
            if (!swsContext_) {
                emit parent_->error(
                    "Could not initialize the conversion context (SwsContext).");
                return false;
            }
        }

        // Prepare input data pointers for sws_scale
        const uint8_t *inData[1] = { rgbFrame.bits() };
        int inLinesize[1] = { int(rgbFrame.bytesPerLine()) };

        // Convert and write to the allocated AVFrame buffer (frame_)
        sws_scale(swsContext_, inData, inLinesize, 0, height_,
                  frame_->data, frame_->linesize);

        // Set the presentation timestamp (PTS) for the frame
        frame_->pts = frameCount_++;

        // 2. Send the frame to the encoder
        int ret = avcodec_send_frame(codecContext_, frame_);
        FF_CHECK(ret, "Error sending frame to encoder.");
    }

    // 3. Receive the encoded packet(s)
    AVPacket *packet = av_packet_alloc();
    if (!packet) {
        emit parent_->error("Could not allocate AVPacket.");
        return false;
    }

    while (true) {
        auto ret = avcodec_receive_packet(codecContext_, packet);

        // AVAGAIN means encoder needs more frames before it can output a packet
        // AVERROR_EOF means the encoder buffer has been flushed
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
            break;
        } else {
            FF_CHECK(ret, "Error receiving packet from encoder.");
        }

        // Rescale timestamp to the stream timebase
        av_packet_rescale_ts(
            packet, codecContext_->time_base, videoStream_->time_base);
        packet->stream_index = videoStream_->index;

        // Write the packet to the output file
        ret = av_interleaved_write_frame(formatContext_, packet);
        av_packet_unref(packet);

        FF_CHECK(ret, "Error writing packet to file.");
    }

    av_packet_free(&packet);

    return true;
}

void VideoRecorder::Impl::cleanupFFmpeg()
{
    // Close the I/O context if it was opened
    if (formatContext_ && !(formatContext_->oformat->flags & AVFMT_NOFILE))
    {
        avio_closep(&formatContext_->pb);
    }
    // Free the format context and all its streams
    if (formatContext_) {
        avformat_free_context(formatContext_);
        formatContext_ = nullptr;
    }
    // Free the codec context
    if (codecContext_) {
        avcodec_free_context(&codecContext_);
        codecContext_ = nullptr;
    }
    // Free the frame
    if (frame_) {
        av_frame_free(&frame_);
        frame_ = nullptr;
    }
    // Free the scaling context
    if (swsContext_) {
        sws_freeContext(swsContext_);
        swsContext_ = nullptr;
    }
    frameCount_ = 0;
    frameQueue_.clear();
}


// ---

VideoRecorder::VideoRecorder(QObject *parent)
    : QObject(parent),
    impl_{new Impl{this}}
{
    connect(impl_, &QThread::started, this, &VideoRecorder::started);
    connect(impl_, &QThread::finished, this, &VideoRecorder::finished);
}

VideoRecorder::~VideoRecorder()
{
    impl_->request_stop();
    impl_->wait();
}

// --- Public Control Functions ---

bool VideoRecorder::start(
    const QString& file_name, int width, int height,
    const VideoRecorderOptions& options)
{
    return impl_->start(file_name, width, height, options);
}

void VideoRecorder::request_stop()
{
    impl_->request_stop();
}

auto VideoRecorder::status() const noexcept -> VideoRecorderStatus
{
    return impl_->status();
}

void VideoRecorder::enqueue_frame(const QImage& frame)
{
    impl_->enqueue_frame(frame);
}
